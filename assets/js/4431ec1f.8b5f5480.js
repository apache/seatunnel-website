"use strict";(self.webpackChunkseatunnel_website=self.webpackChunkseatunnel_website||[]).push([[77066,20141],{15680:(e,t,a)=>{a.d(t,{xA:()=>m,yg:()=>s});var n=a(96540);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function g(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var p=n.createContext({}),o=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},m=function(e){var t=o(e.components);return n.createElement(p.Provider,{value:t},e.children)},d="mdxType",y={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,r=e.originalType,p=e.parentName,m=g(e,["components","mdxType","originalType","parentName"]),d=o(a),u=l,s=d["".concat(p,".").concat(u)]||d[u]||y[u]||r;return a?n.createElement(s,i(i({ref:t},m),{},{components:a})):n.createElement(s,i({ref:t},m))}));function s(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=a.length,i=new Array(r);i[0]=u;var g={};for(var p in t)hasOwnProperty.call(t,p)&&(g[p]=t[p]);g.originalType=e,g[d]="string"==typeof e?e:l,i[1]=g;for(var o=2;o<r;o++)i[o]=a[o];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},20037:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>y,frontMatter:()=>r,metadata:()=>g,toc:()=>o});var n=a(58168),l=(a(96540),a(15680));const r={},i=void 0,g={unversionedId:"connector-v2/changelog/connector-file-s3",id:"connector-v2/changelog/connector-file-s3",title:"connector-file-s3",description:"Change Log",source:"@site/docs/connector-v2/changelog/connector-file-s3.md",sourceDirName:"connector-v2/changelog",slug:"/connector-v2/changelog/connector-file-s3",permalink:"/docs/connector-v2/changelog/connector-file-s3",draft:!1,editUrl:"https://github.com/apache/seatunnel-website/edit/main/docs/connector-v2/changelog/connector-file-s3.md",tags:[],version:"current",frontMatter:{}},p={},o=[],m={toc:o},d="wrapper";function y(e){let{components:t,...a}=e;return(0,l.yg)(d,(0,n.A)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,l.yg)("details",null,(0,l.yg)("summary",null," Change Log "),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Change"),(0,l.yg)("th",{parentName:"tr",align:null},"Commit"),(0,l.yg)("th",{parentName:"tr",align:null},"Version"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][File]"," Add row_delimiter options into text file sink (#9017)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/92aa855a34"},"https://github.com/apache/seatunnel/commit/92aa855a34")),(0,l.yg)("td",{parentName:"tr",align:null},"dev")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Revert ",'"'," ","[improve]"," update localfile connector config",'"'," (#9018)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/cdc79e13ad"},"https://github.com/apache/seatunnel/commit/cdc79e13ad")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.10")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[improve]"," update localfile connector config (#8765)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/def369a85f"},"https://github.com/apache/seatunnel/commit/def369a85f")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.10")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Fix][Connector-V2]"," Fixed incorrectly setting s3 key in some cases (#8885)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/cf4bab5be2"},"https://github.com/apache/seatunnel/commit/cf4bab5be2")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.10")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector-V2]"," Add ",(0,l.yg)("inlineCode",{parentName:"td"},"filename_extension")," parameter for read/write file (#8769)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/78b23c0ef5"},"https://github.com/apache/seatunnel/commit/78b23c0ef5")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.10")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve]"," restruct connector common options (#8634)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/f3499a6eeb"},"https://github.com/apache/seatunnel/commit/f3499a6eeb")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.10")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[improve]"," update S3File connector config option  (#8615)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/80cc9fa6ff"},"https://github.com/apache/seatunnel/commit/80cc9fa6ff")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.10")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector-V2]"," Support create emtpy file when no data (#8543)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/275db78918"},"https://github.com/apache/seatunnel/commit/275db78918")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.10")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector-V2]"," Support single file mode in file sink (#8518)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/e893deed50"},"https://github.com/apache/seatunnel/commit/e893deed50")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.10")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][File]"," Support config null format for text file read (#8109)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/2dbf02df47"},"https://github.com/apache/seatunnel/commit/2dbf02df47")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.9")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Hotfix][Zeta]"," Fix the dependency conflict between the guava in hadoop-aws and hive-exec (#7986)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/a7837f1f19"},"https://github.com/apache/seatunnel/commit/a7837f1f19")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.9")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Restapi]"," Allow metrics information to be associated to logical plan nodes (#7786)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/6b7c53d03c"},"https://github.com/apache/seatunnel/commit/6b7c53d03c")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.9")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Connector-V2]"," Support read archive compress file (#7633)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/3f98cd8a16"},"https://github.com/apache/seatunnel/commit/3f98cd8a16")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.8")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve]"," Refactor S3FileCatalog and it","'","s factory (#7457)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/d928e8b113"},"https://github.com/apache/seatunnel/commit/d928e8b113")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.8")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Connector]"," Add multi-table sink option check (#7360)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/2489f6446b"},"https://github.com/apache/seatunnel/commit/2489f6446b")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.7")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Core]"," Support using upstream table placeholders in sink options and auto replacement (#7131)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/c4ca74122c"},"https://github.com/apache/seatunnel/commit/c4ca74122c")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.6")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Files]"," Support write fixed/timestamp as int96 of parquet (#6971)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/1a48a9c493"},"https://github.com/apache/seatunnel/commit/1a48a9c493")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.6")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][S3 File]"," Make S3 File Connector support multiple table write (#6698)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/8f2049b2f1"},"https://github.com/apache/seatunnel/commit/8f2049b2f1")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.6")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Connector-v2]"," The hive connector support multiple filesystem (#6648)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/8a4c01fe35"},"https://github.com/apache/seatunnel/commit/8a4c01fe35")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.6")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[bigfix][S3 File]",":Change the ","[SCHEMA]"," attribute of the ","[S3CONF class]"," to be non-static to avoid being reassigned after deserialization (#6717)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/79bb70101a"},"https://github.com/apache/seatunnel/commit/79bb70101a")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.6")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Fix][Connector-V2]"," Fix connector support SPI but without no args constructor (#6551)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/5f3c9c36a5"},"https://github.com/apache/seatunnel/commit/5f3c9c36a5")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.5")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Add support for XML file type to various file connectors such as SFTP, FTP, LocalFile, HdfsFile, and more. (#6327)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/ec533ecd9a"},"https://github.com/apache/seatunnel/commit/ec533ecd9a")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.5")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Test][E2E]"," Add thread leak check for connector (#5773)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/1f2f3fc5f0"},"https://github.com/apache/seatunnel/commit/1f2f3fc5f0")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector]","add s3file save mode function (#6131)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/81c51073bf"},"https://github.com/apache/seatunnel/commit/81c51073bf")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Refactor][File Connector]"," Put Multiple Table File API to File Base Module (#6033)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/c324d663b4"},"https://github.com/apache/seatunnel/commit/c324d663b4")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Support using multiple hadoop account (#5903)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/d69d88d1aa"},"https://github.com/apache/seatunnel/commit/d69d88d1aa")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Common]"," Introduce new error define rule (#5793)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/9d1b2582b2"},"https://github.com/apache/seatunnel/commit/9d1b2582b2")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][connector-file]"," unifiy option between file source/sink and update document (#5680)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/8d87cf8fc4"},"https://github.com/apache/seatunnel/commit/8d87cf8fc4")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature]"," Support ",(0,l.yg)("inlineCode",{parentName:"td"},"LZO")," compress on File Read (#5083)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/a4a1901096"},"https://github.com/apache/seatunnel/commit/a4a1901096")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector-V2]","[File]"," Support read empty directory (#5591)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/1f58f224a0"},"https://github.com/apache/seatunnel/commit/1f58f224a0")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Support config column/primaryKey/constraintKey in schema (#5564)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/eac76b4e50"},"https://github.com/apache/seatunnel/commit/eac76b4e50")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][File Connector]","optionrule FILE_FORMAT_TYPE is text/csv ,add parameter BaseSinkConfig.ENABLE_HEADER_WRITE: #5566 (#5567)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/0e02db768d"},"https://github.com/apache/seatunnel/commit/0e02db768d")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.4")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector V2]","[File]"," Add config of ","'","file_filter_pattern","'",", which used for filtering files. (#5153)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/a3c13e59eb"},"https://github.com/apache/seatunnel/commit/a3c13e59eb")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.3")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[chore]"," delete unavailable S3 ","&"," Kafka Catalogs (#4477)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/e0aec5ecec"},"https://github.com/apache/seatunnel/commit/e0aec5ecec")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.2")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][ConnectorV2]","add file excel sink and source (#4164)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/e3b97ae5d2"},"https://github.com/apache/seatunnel/commit/e3b97ae5d2")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.2")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Change file type to file_format_type in file source/sink (#4249)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/973a2fae3c"},"https://github.com/apache/seatunnel/commit/973a2fae3c")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Chore]"," Upgrade guava to 27.0-jre (#4238)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/4851bee575"},"https://github.com/apache/seatunnel/commit/4851bee575")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Add redshift datatype convertor (#4245)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/b19011517f"},"https://github.com/apache/seatunnel/commit/b19011517f")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Merge branch ","'","dev","'"," into merge/cdc"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/4324ee1912"},"https://github.com/apache/seatunnel/commit/4324ee1912")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Project]"," Code format with spotless plugin."),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/423b583038"},"https://github.com/apache/seatunnel/commit/423b583038")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[improve][api]"," Refactoring schema parse (#4157)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/b2f573a13e"},"https://github.com/apache/seatunnel/commit/b2f573a13e")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][build]"," Give the maven module a human readable name (#4114)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/d7cd601051"},"https://github.com/apache/seatunnel/commit/d7cd601051")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Add S3Catalog (#4121)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/7d7f506547"},"https://github.com/apache/seatunnel/commit/7d7f506547")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Project]"," Code format with spotless plugin. (#4101)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/a2ab166561"},"https://github.com/apache/seatunnel/commit/a2ab166561")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector-V2]","[File]"," Support compress (#3899)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/55602f6b1c"},"https://github.com/apache/seatunnel/commit/55602f6b1c")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector]"," add get source method to all source connector (#3846)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/417178fb84"},"https://github.com/apache/seatunnel/commit/417178fb84")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Connector-V2]","[File]"," Improve file connector option rule and document (#3812)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/bd76077669"},"https://github.com/apache/seatunnel/commit/bd76077669")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.1")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Shade]"," Add seatunnel hadoop3 uber (#3755)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/5a024bdf8f"},"https://github.com/apache/seatunnel/commit/5a024bdf8f")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Engine][Checkpoint]","Unified naming style (#3714)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/bc0bd3bec3"},"https://github.com/apache/seatunnel/commit/bc0bd3bec3")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Connector][File-S3]","Set AK is not required (#3713)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/da3c526172"},"https://github.com/apache/seatunnel/commit/da3c526172")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Connector","&","Engine]","Set S3 AK to optional (#3688)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/4710918b02"},"https://github.com/apache/seatunnel/commit/4710918b02")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Connector][S3]","Support s3a protocol (#3632)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/ae4cc9c1ec"},"https://github.com/apache/seatunnel/commit/ae4cc9c1ec")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Hotfix][OptionRule]"," Fix option rule about all connectors (#3592)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/226dc6a119"},"https://github.com/apache/seatunnel/commit/226dc6a119")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Connector-V2]","[File]"," Unified excetion for file source ","&"," sink connectors (#3525)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/031e8e263c"},"https://github.com/apache/seatunnel/commit/031e8e263c")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector-V2]","[File]"," Add option and factory for file connectors (#3375)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/db286e8631"},"https://github.com/apache/seatunnel/commit/db286e8631")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Improve][Connector-V2]","[File]"," Improve code structure (#3238)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/dd5c353881"},"https://github.com/apache/seatunnel/commit/dd5c353881")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Connector-V2][ElasticSearch]"," Add ElasticSearch Source/Sink Factory (#3325)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/38254e3f26"},"https://github.com/apache/seatunnel/commit/38254e3f26")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"[Feature][Connector-V2]","[S3]"," Add S3 file source ","&"," sink connector (#3119)"),(0,l.yg)("td",{parentName:"tr",align:null},(0,l.yg)("a",{parentName:"td",href:"https://github.com/apache/seatunnel/commit/f27d68ca9c"},"https://github.com/apache/seatunnel/commit/f27d68ca9c")),(0,l.yg)("td",{parentName:"tr",align:null},"2.3.0-beta"))))))}y.isMDXComponent=!0},63891:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>g,default:()=>u,frontMatter:()=>i,metadata:()=>p,toc:()=>m});var n=a(58168),l=(a(96540),a(15680)),r=a(20037);const i={},g="S3File",p={unversionedId:"connector-v2/source/S3File",id:"connector-v2/source/S3File",title:"S3File",description:"S3 File Source Connector",source:"@site/docs/connector-v2/source/S3File.md",sourceDirName:"connector-v2/source",slug:"/connector-v2/source/S3File",permalink:"/docs/connector-v2/source/S3File",draft:!1,editUrl:"https://github.com/apache/seatunnel-website/edit/main/docs/connector-v2/source/S3File.md",tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"RocketMQ",permalink:"/docs/connector-v2/source/RocketMQ"},next:{title:"SftpFile",permalink:"/docs/connector-v2/source/SftpFile"}},o={},m=[{value:"Support Those Engines",id:"support-those-engines",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Description",id:"description",level:2},{value:"Supported DataSource Info",id:"supported-datasource-info",level:2},{value:"Dependency",id:"dependency",level:2},{value:"Data Type Mapping",id:"data-type-mapping",level:2},{value:"JSON File Type",id:"json-file-type",level:3},{value:"Text Or CSV File Type",id:"text-or-csv-file-type",level:3},{value:"Orc File Type",id:"orc-file-type",level:3},{value:"Parquet File Type",id:"parquet-file-type",level:3},{value:"Options",id:"options",level:2},{value:"delimiter/field_delimiter string",id:"delimiterfield_delimiter-string",level:3},{value:"file_filter_pattern string",id:"file_filter_pattern-string",level:3},{value:"compress_codec string",id:"compress_codec-string",level:3},{value:"archive_compress_codec string",id:"archive_compress_codec-string",level:3},{value:"encoding string",id:"encoding-string",level:3},{value:"Example",id:"example",level:2},{value:"Filter File",id:"filter-file",level:3},{value:"Changelog",id:"changelog",level:2},{value:"2.3.0-beta 2022-10-20",id:"230-beta-2022-10-20",level:3},{value:"Next version",id:"next-version",level:3},{value:"Changelog",id:"changelog-1",level:2}],d={toc:m},y="wrapper";function u(e){let{components:t,...a}=e;return(0,l.yg)(y,(0,n.A)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,l.yg)("h1",{id:"s3file"},"S3File"),(0,l.yg)("blockquote",null,(0,l.yg)("p",{parentName:"blockquote"},"S3 File Source Connector")),(0,l.yg)("h2",{id:"support-those-engines"},"Support Those Engines"),(0,l.yg)("blockquote",null,(0,l.yg)("p",{parentName:"blockquote"},"Spark",(0,l.yg)("br",null),"\nFlink",(0,l.yg)("br",null),"\nSeaTunnel Zeta",(0,l.yg)("br",null))),(0,l.yg)("h2",{id:"key-features"},"Key Features"),(0,l.yg)("ul",{className:"contains-task-list"},(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ",(0,l.yg)("a",{parentName:"li",href:"/docs/concept/connector-v2-features"},"batch")),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!1,disabled:!0})," ",(0,l.yg)("a",{parentName:"li",href:"/docs/concept/connector-v2-features"},"stream")),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ",(0,l.yg)("a",{parentName:"li",href:"/docs/concept/connector-v2-features"},"exactly-once"))),(0,l.yg)("p",null,"Read all the data in a split in a pollNext call. What splits are read will be saved in snapshot."),(0,l.yg)("ul",{className:"contains-task-list"},(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ",(0,l.yg)("a",{parentName:"li",href:"/docs/concept/connector-v2-features"},"column projection")),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ",(0,l.yg)("a",{parentName:"li",href:"/docs/concept/connector-v2-features"},"parallelism")),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!1,disabled:!0})," ",(0,l.yg)("a",{parentName:"li",href:"/docs/concept/connector-v2-features"},"support user-defined split")),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","file format type",(0,l.yg)("ul",{parentName:"li",className:"contains-task-list"},(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","text"),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","csv"),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","parquet"),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","orc"),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","json"),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","excel"),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","xml"),(0,l.yg)("li",{parentName:"ul",className:"task-list-item"},(0,l.yg)("input",{parentName:"li",type:"checkbox",checked:!0,disabled:!0})," ","binary")))),(0,l.yg)("h2",{id:"description"},"Description"),(0,l.yg)("p",null,"Read data from aws s3 file system."),(0,l.yg)("h2",{id:"supported-datasource-info"},"Supported DataSource Info"),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Datasource"),(0,l.yg)("th",{parentName:"tr",align:null},"Supported versions"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"S3"),(0,l.yg)("td",{parentName:"tr",align:null},"current")))),(0,l.yg)("h2",{id:"dependency"},"Dependency"),(0,l.yg)("blockquote",null,(0,l.yg)("p",{parentName:"blockquote"},"If you use spark/flink, In order to use this connector, You must ensure your spark/flink cluster already integrated hadoop. The tested hadoop version is 2.x.",(0,l.yg)("br",null)),(0,l.yg)("p",{parentName:"blockquote"},"If you use SeaTunnel Zeta, It automatically integrated the hadoop jar when you download and install SeaTunnel Zeta. You can check the jar package under ${SEATUNNEL_HOME}/lib to confirm this.",(0,l.yg)("br",null),"\nTo use this connector you need put hadoop-aws-3.1.4.jar and aws-java-sdk-bundle-1.12.692.jar in ${SEATUNNEL_HOME}/lib dir.")),(0,l.yg)("h2",{id:"data-type-mapping"},"Data Type Mapping"),(0,l.yg)("p",null,"Data type mapping is related to the type of file being read, We supported as the following file types:"),(0,l.yg)("p",null,(0,l.yg)("inlineCode",{parentName:"p"},"text")," ",(0,l.yg)("inlineCode",{parentName:"p"},"csv")," ",(0,l.yg)("inlineCode",{parentName:"p"},"parquet")," ",(0,l.yg)("inlineCode",{parentName:"p"},"orc")," ",(0,l.yg)("inlineCode",{parentName:"p"},"json")," ",(0,l.yg)("inlineCode",{parentName:"p"},"excel")," ",(0,l.yg)("inlineCode",{parentName:"p"},"xml")),(0,l.yg)("h3",{id:"json-file-type"},"JSON File Type"),(0,l.yg)("p",null,"If you assign file type to ",(0,l.yg)("inlineCode",{parentName:"p"},"json"),", you should also assign schema option to tell connector how to parse data to the row you want."),(0,l.yg)("p",null,"For example:"),(0,l.yg)("p",null,"upstream data is the following:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json"},'\n{"code":  200, "data":  "get success", "success":  true}\n\n')),(0,l.yg)("p",null,"You can also save multiple pieces of data in one file and split them by newline:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-json",metastring:"lines",lines:!0},'\n{"code":  200, "data":  "get success", "success":  true}\n{"code":  300, "data":  "get failed", "success":  false}\n\n')),(0,l.yg)("p",null,"you should assign schema as the following:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-hocon"},"\nschema {\n    fields {\n        code = int\n        data = string\n        success = boolean\n    }\n}\n\n")),(0,l.yg)("p",null,"connector will generate data as the following:"),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"code"),(0,l.yg)("th",{parentName:"tr",align:null},"data"),(0,l.yg)("th",{parentName:"tr",align:null},"success"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"200"),(0,l.yg)("td",{parentName:"tr",align:null},"get success"),(0,l.yg)("td",{parentName:"tr",align:null},"true")))),(0,l.yg)("h3",{id:"text-or-csv-file-type"},"Text Or CSV File Type"),(0,l.yg)("p",null,"If you set the ",(0,l.yg)("inlineCode",{parentName:"p"},"file_format_type")," to ",(0,l.yg)("inlineCode",{parentName:"p"},"text"),",",(0,l.yg)("inlineCode",{parentName:"p"},"excel"),",",(0,l.yg)("inlineCode",{parentName:"p"},"csv"),",",(0,l.yg)("inlineCode",{parentName:"p"},"xml"),". Then it's required to set the ",(0,l.yg)("inlineCode",{parentName:"p"},"schema")," field to tell connector how to parse data to the row."),(0,l.yg)("p",null,"If you set the ",(0,l.yg)("inlineCode",{parentName:"p"},"schema")," field, you should also set the option ",(0,l.yg)("inlineCode",{parentName:"p"},"field_delimiter"),", except the ",(0,l.yg)("inlineCode",{parentName:"p"},"file_format_type")," is ",(0,l.yg)("inlineCode",{parentName:"p"},"csv"),", ",(0,l.yg)("inlineCode",{parentName:"p"},"xml"),", ",(0,l.yg)("inlineCode",{parentName:"p"},"excel")),(0,l.yg)("p",null,"you can set schema and delimiter as the following:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-hocon"},'\nfield_delimiter = "#"\nschema {\n    fields {\n        name = string\n        age = int\n        gender = string \n    }\n}\n\n')),(0,l.yg)("p",null,"connector will generate data as the following:"),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"name"),(0,l.yg)("th",{parentName:"tr",align:null},"age"),(0,l.yg)("th",{parentName:"tr",align:null},"gender"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"tyrantlucifer"),(0,l.yg)("td",{parentName:"tr",align:null},"26"),(0,l.yg)("td",{parentName:"tr",align:null},"male")))),(0,l.yg)("h3",{id:"orc-file-type"},"Orc File Type"),(0,l.yg)("p",null,"If you assign file type to ",(0,l.yg)("inlineCode",{parentName:"p"},"parquet")," ",(0,l.yg)("inlineCode",{parentName:"p"},"orc"),", schema option not required, connector can find the schema of upstream data automatically."),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Orc Data type"),(0,l.yg)("th",{parentName:"tr",align:null},"SeaTunnel Data type"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"BOOLEAN"),(0,l.yg)("td",{parentName:"tr",align:null},"BOOLEAN")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"INT"),(0,l.yg)("td",{parentName:"tr",align:null},"INT")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"BYTE"),(0,l.yg)("td",{parentName:"tr",align:null},"BYTE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"SHORT"),(0,l.yg)("td",{parentName:"tr",align:null},"SHORT")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LONG"),(0,l.yg)("td",{parentName:"tr",align:null},"LONG")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"FLOAT"),(0,l.yg)("td",{parentName:"tr",align:null},"FLOAT")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"DOUBLE"),(0,l.yg)("td",{parentName:"tr",align:null},"DOUBLE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"BINARY"),(0,l.yg)("td",{parentName:"tr",align:null},"BINARY")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"STRING",(0,l.yg)("br",null),"VARCHAR",(0,l.yg)("br",null),"CHAR",(0,l.yg)("br",null)),(0,l.yg)("td",{parentName:"tr",align:null},"STRING")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"DATE"),(0,l.yg)("td",{parentName:"tr",align:null},"LOCAL_DATE_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"TIMESTAMP"),(0,l.yg)("td",{parentName:"tr",align:null},"LOCAL_DATE_TIME_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"DECIMAL"),(0,l.yg)("td",{parentName:"tr",align:null},"DECIMAL")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(STRING)"),(0,l.yg)("td",{parentName:"tr",align:null},"STRING_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(BOOLEAN)"),(0,l.yg)("td",{parentName:"tr",align:null},"BOOLEAN_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(TINYINT)"),(0,l.yg)("td",{parentName:"tr",align:null},"BYTE_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(SMALLINT)"),(0,l.yg)("td",{parentName:"tr",align:null},"SHORT_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(INT)"),(0,l.yg)("td",{parentName:"tr",align:null},"INT_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(BIGINT)"),(0,l.yg)("td",{parentName:"tr",align:null},"LONG_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(FLOAT)"),(0,l.yg)("td",{parentName:"tr",align:null},"FLOAT_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(DOUBLE)"),(0,l.yg)("td",{parentName:"tr",align:null},"DOUBLE_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Map<K,V>"),(0,l.yg)("td",{parentName:"tr",align:null},"MapType, This type of K and V will transform to SeaTunnel type")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"STRUCT"),(0,l.yg)("td",{parentName:"tr",align:null},"SeaTunnelRowType")))),(0,l.yg)("h3",{id:"parquet-file-type"},"Parquet File Type"),(0,l.yg)("p",null,"If you assign file type to ",(0,l.yg)("inlineCode",{parentName:"p"},"parquet")," ",(0,l.yg)("inlineCode",{parentName:"p"},"orc"),", schema option not required, connector can find the schema of upstream data automatically."),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"Parquet Data type"),(0,l.yg)("th",{parentName:"tr",align:null},"SeaTunnel Data type"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"INT_8"),(0,l.yg)("td",{parentName:"tr",align:null},"BYTE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"INT_16"),(0,l.yg)("td",{parentName:"tr",align:null},"SHORT")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"DATE"),(0,l.yg)("td",{parentName:"tr",align:null},"DATE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"TIMESTAMP_MILLIS"),(0,l.yg)("td",{parentName:"tr",align:null},"TIMESTAMP")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"INT64"),(0,l.yg)("td",{parentName:"tr",align:null},"LONG")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"INT96"),(0,l.yg)("td",{parentName:"tr",align:null},"TIMESTAMP")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"BINARY"),(0,l.yg)("td",{parentName:"tr",align:null},"BYTES")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"FLOAT"),(0,l.yg)("td",{parentName:"tr",align:null},"FLOAT")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"DOUBLE"),(0,l.yg)("td",{parentName:"tr",align:null},"DOUBLE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"BOOLEAN"),(0,l.yg)("td",{parentName:"tr",align:null},"BOOLEAN")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"FIXED_LEN_BYTE_ARRAY"),(0,l.yg)("td",{parentName:"tr",align:null},"TIMESTAMP",(0,l.yg)("br",null)," DECIMAL")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"DECIMAL"),(0,l.yg)("td",{parentName:"tr",align:null},"DECIMAL")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(STRING)"),(0,l.yg)("td",{parentName:"tr",align:null},"STRING_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(BOOLEAN)"),(0,l.yg)("td",{parentName:"tr",align:null},"BOOLEAN_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(TINYINT)"),(0,l.yg)("td",{parentName:"tr",align:null},"BYTE_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(SMALLINT)"),(0,l.yg)("td",{parentName:"tr",align:null},"SHORT_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(INT)"),(0,l.yg)("td",{parentName:"tr",align:null},"INT_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(BIGINT)"),(0,l.yg)("td",{parentName:"tr",align:null},"LONG_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(FLOAT)"),(0,l.yg)("td",{parentName:"tr",align:null},"FLOAT_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"LIST(DOUBLE)"),(0,l.yg)("td",{parentName:"tr",align:null},"DOUBLE_ARRAY_TYPE")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"Map<K,V>"),(0,l.yg)("td",{parentName:"tr",align:null},"MapType, This type of K and V will transform to SeaTunnel type")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"STRUCT"),(0,l.yg)("td",{parentName:"tr",align:null},"SeaTunnelRowType")))),(0,l.yg)("h2",{id:"options"},"Options"),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"name"),(0,l.yg)("th",{parentName:"tr",align:null},"type"),(0,l.yg)("th",{parentName:"tr",align:null},"required"),(0,l.yg)("th",{parentName:"tr",align:null},"default value"),(0,l.yg)("th",{parentName:"tr",align:null},"Description"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"path"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"yes"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},'The s3 path that needs to be read can have sub paths, but the sub paths need to meet certain format requirements. Specific requirements can be referred to "parse_partition_from_path" option')),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"file_format_type"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"yes"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"File type, supported as the following file types: ",(0,l.yg)("inlineCode",{parentName:"td"},"text")," ",(0,l.yg)("inlineCode",{parentName:"td"},"csv")," ",(0,l.yg)("inlineCode",{parentName:"td"},"parquet")," ",(0,l.yg)("inlineCode",{parentName:"td"},"orc")," ",(0,l.yg)("inlineCode",{parentName:"td"},"json")," ",(0,l.yg)("inlineCode",{parentName:"td"},"excel")," ",(0,l.yg)("inlineCode",{parentName:"td"},"xml")," ",(0,l.yg)("inlineCode",{parentName:"td"},"binary"))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"bucket"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"yes"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"The bucket address of s3 file system, for example: ",(0,l.yg)("inlineCode",{parentName:"td"},"s3n://seatunnel-test"),", if you use ",(0,l.yg)("inlineCode",{parentName:"td"},"s3a")," protocol, this parameter should be ",(0,l.yg)("inlineCode",{parentName:"td"},"s3a://seatunnel-test"),".")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"fs.s3a.endpoint"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"yes"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"fs s3a endpoint")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"fs.s3a.aws.credentials.provider"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"yes"),(0,l.yg)("td",{parentName:"tr",align:null},"com.amazonaws.auth.InstanceProfileCredentialsProvider"),(0,l.yg)("td",{parentName:"tr",align:null},"The way to authenticate s3a. We only support ",(0,l.yg)("inlineCode",{parentName:"td"},"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider")," and ",(0,l.yg)("inlineCode",{parentName:"td"},"com.amazonaws.auth.InstanceProfileCredentialsProvider")," now. More information about the credential provider you can see ",(0,l.yg)("a",{parentName:"td",href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html#Simple_name.2Fsecret_credentials_with_SimpleAWSCredentialsProvider.2A"},"Hadoop AWS Document"))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"read_columns"),(0,l.yg)("td",{parentName:"tr",align:null},"list"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"The read column list of the data source, user can use it to implement field projection. The file type supported column projection as the following shown: ",(0,l.yg)("inlineCode",{parentName:"td"},"text")," ",(0,l.yg)("inlineCode",{parentName:"td"},"csv")," ",(0,l.yg)("inlineCode",{parentName:"td"},"parquet")," ",(0,l.yg)("inlineCode",{parentName:"td"},"orc")," ",(0,l.yg)("inlineCode",{parentName:"td"},"json")," ",(0,l.yg)("inlineCode",{parentName:"td"},"excel")," ",(0,l.yg)("inlineCode",{parentName:"td"},"xml")," . If the user wants to use this feature when reading ",(0,l.yg)("inlineCode",{parentName:"td"},"text")," ",(0,l.yg)("inlineCode",{parentName:"td"},"json")," ",(0,l.yg)("inlineCode",{parentName:"td"},"csv"),' files, the "schema" option must be configured.')),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"access_key"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"Only used when ",(0,l.yg)("inlineCode",{parentName:"td"},"fs.s3a.aws.credentials.provider = org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider "))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"access_secret"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"Only used when ",(0,l.yg)("inlineCode",{parentName:"td"},"fs.s3a.aws.credentials.provider = org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider "))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"hadoop_s3_properties"),(0,l.yg)("td",{parentName:"tr",align:null},"map"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"If you need to add other option, you could add it here and refer to this ",(0,l.yg)("a",{parentName:"td",href:"https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html"},"link"))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"delimiter/field_delimiter"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"\\001"),(0,l.yg)("td",{parentName:"tr",align:null},"Field delimiter, used to tell connector how to slice and dice fields when reading text files. Default ",(0,l.yg)("inlineCode",{parentName:"td"},"\\001"),", the same as hive's default delimiter.")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"parse_partition_from_path"),(0,l.yg)("td",{parentName:"tr",align:null},"boolean"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"true"),(0,l.yg)("td",{parentName:"tr",align:null},"Control whether parse the partition keys and values from file path. For example if you read a file from path ",(0,l.yg)("inlineCode",{parentName:"td"},"s3n://hadoop-cluster/tmp/seatunnel/parquet/name=tyrantlucifer/age=26"),'. Every record data from file will be added these two fields: name="tyrantlucifer", age=16')),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"date_format"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"yyyy-MM-dd"),(0,l.yg)("td",{parentName:"tr",align:null},"Date type format, used to tell connector how to convert string to date, supported as the following formats:",(0,l.yg)("inlineCode",{parentName:"td"},"yyyy-MM-dd")," ",(0,l.yg)("inlineCode",{parentName:"td"},"yyyy.MM.dd")," ",(0,l.yg)("inlineCode",{parentName:"td"},"yyyy/MM/dd"),". default ",(0,l.yg)("inlineCode",{parentName:"td"},"yyyy-MM-dd"))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"datetime_format"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"yyyy-MM-dd HH:mm:ss"),(0,l.yg)("td",{parentName:"tr",align:null},"Datetime type format, used to tell connector how to convert string to datetime, supported as the following formats:",(0,l.yg)("inlineCode",{parentName:"td"},"yyyy-MM-dd HH:mm:ss")," ",(0,l.yg)("inlineCode",{parentName:"td"},"yyyy.MM.dd HH:mm:ss")," ",(0,l.yg)("inlineCode",{parentName:"td"},"yyyy/MM/dd HH:mm:ss")," ",(0,l.yg)("inlineCode",{parentName:"td"},"yyyyMMddHHmmss"))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"time_format"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"HH:mm:ss"),(0,l.yg)("td",{parentName:"tr",align:null},"Time type format, used to tell connector how to convert string to time, supported as the following formats:",(0,l.yg)("inlineCode",{parentName:"td"},"HH:mm:ss")," ",(0,l.yg)("inlineCode",{parentName:"td"},"HH:mm:ss.SSS"))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"skip_header_row_number"),(0,l.yg)("td",{parentName:"tr",align:null},"long"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"0"),(0,l.yg)("td",{parentName:"tr",align:null},"Skip the first few lines, but only for the txt and csv. For example, set like following:",(0,l.yg)("inlineCode",{parentName:"td"},"skip_header_row_number = 2"),". Then SeaTunnel will skip the first 2 lines from source files")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"csv_use_header_line"),(0,l.yg)("td",{parentName:"tr",align:null},"boolean"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"false"),(0,l.yg)("td",{parentName:"tr",align:null},"Whether to use the header line to parse the file, only used when the file_format is ",(0,l.yg)("inlineCode",{parentName:"td"},"csv")," and the file contains the header line that match RFC 4180")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"schema"),(0,l.yg)("td",{parentName:"tr",align:null},"config"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"The schema of upstream data.")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"sheet_name"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"Reader the sheet of the workbook,Only used when file_format is excel.")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"xml_row_tag"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"Specifies the tag name of the data rows within the XML file, only valid for XML files.")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"xml_use_attr_format"),(0,l.yg)("td",{parentName:"tr",align:null},"boolean"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"Specifies whether to process data using the tag attribute format, only valid for XML files.")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"csv_use_header_line"),(0,l.yg)("td",{parentName:"tr",align:null},"boolean"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"false"),(0,l.yg)("td",{parentName:"tr",align:null},"Whether to use the header line to parse the file, only used when the file_format is ",(0,l.yg)("inlineCode",{parentName:"td"},"csv")," and the file contains the header line that match RFC 4180")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"compress_codec"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"none"),(0,l.yg)("td",{parentName:"tr",align:null})),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"archive_compress_codec"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"none"),(0,l.yg)("td",{parentName:"tr",align:null})),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"encoding"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"UTF-8"),(0,l.yg)("td",{parentName:"tr",align:null})),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"null_format"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"Only used when file_format_type is text. null_format to define which strings can be represented as null. e.g: ",(0,l.yg)("inlineCode",{parentName:"td"},"\\N"))),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"file_filter_pattern"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null}),(0,l.yg)("td",{parentName:"tr",align:null},"Filter pattern, which used for filtering files.")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"filename_extension"),(0,l.yg)("td",{parentName:"tr",align:null},"string"),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"Filter filename extension, which used for filtering files with specific extension. Example: ",(0,l.yg)("inlineCode",{parentName:"td"},"csv")," ",(0,l.yg)("inlineCode",{parentName:"td"},".txt")," ",(0,l.yg)("inlineCode",{parentName:"td"},"json")," ",(0,l.yg)("inlineCode",{parentName:"td"},".xml"),".")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"common-options"),(0,l.yg)("td",{parentName:"tr",align:null}),(0,l.yg)("td",{parentName:"tr",align:null},"no"),(0,l.yg)("td",{parentName:"tr",align:null},"-"),(0,l.yg)("td",{parentName:"tr",align:null},"Source plugin common parameters, please refer to ",(0,l.yg)("a",{parentName:"td",href:"/docs/connector-v2/source-common-options"},"Source Common Options")," for details.")))),(0,l.yg)("h3",{id:"delimiterfield_delimiter-string"},"delimiter/field_delimiter ","[string]"),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"delimiter")," parameter will deprecate after version 2.3.5, please use ",(0,l.yg)("strong",{parentName:"p"},"field_delimiter")," instead."),(0,l.yg)("h3",{id:"file_filter_pattern-string"},"file_filter_pattern ","[string]"),(0,l.yg)("p",null,"Filter pattern, which used for filtering files."),(0,l.yg)("p",null,"The pattern follows standard regular expressions. For details, please refer to ",(0,l.yg)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Regular_expression"},"https://en.wikipedia.org/wiki/Regular_expression"),".\nThere are some examples."),(0,l.yg)("p",null,"File Structure Example:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/20241001/report.txt\n/data/seatunnel/20241007/abch202410.csv\n/data/seatunnel/20241002/abcg202410.csv\n/data/seatunnel/20241005/old_data.csv\n/data/seatunnel/20241012/logo.png\n")),(0,l.yg)("p",null,"Matching Rules Example:"),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"Example 1"),": ",(0,l.yg)("em",{parentName:"p"},"Match all .txt files"),"\uff0cRegular Expression:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/20241001/.*\\.txt\n")),(0,l.yg)("p",null,"The result of this example matching is:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/20241001/report.txt\n")),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"Example 2"),": ",(0,l.yg)("em",{parentName:"p"},"Match all file starting with abc"),"\uff0cRegular Expression:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/20241002/abc.*\n")),(0,l.yg)("p",null,"The result of this example matching is:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/20241007/abch202410.csv\n/data/seatunnel/20241002/abcg202410.csv\n")),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"Example 3"),": ",(0,l.yg)("em",{parentName:"p"},"Match all file starting with abc\uff0cAnd the fourth character is either h or g"),", the Regular Expression:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/20241007/abc[h,g].*\n")),(0,l.yg)("p",null,"The result of this example matching is:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/20241007/abch202410.csv\n")),(0,l.yg)("p",null,(0,l.yg)("strong",{parentName:"p"},"Example 4"),": ",(0,l.yg)("em",{parentName:"p"},"Match third level folders starting with 202410 and files ending with .csv"),", the Regular Expression:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/202410\\d*/.*\\.csv\n")),(0,l.yg)("p",null,"The result of this example matching is:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"/data/seatunnel/20241007/abch202410.csv\n/data/seatunnel/20241002/abcg202410.csv\n/data/seatunnel/20241005/old_data.csv\n")),(0,l.yg)("h3",{id:"compress_codec-string"},"compress_codec ","[string]"),(0,l.yg)("p",null,"The compress codec of files and the details that supported as the following shown:"),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},"txt: ",(0,l.yg)("inlineCode",{parentName:"li"},"lzo")," ",(0,l.yg)("inlineCode",{parentName:"li"},"none")),(0,l.yg)("li",{parentName:"ul"},"json: ",(0,l.yg)("inlineCode",{parentName:"li"},"lzo")," ",(0,l.yg)("inlineCode",{parentName:"li"},"none")),(0,l.yg)("li",{parentName:"ul"},"csv: ",(0,l.yg)("inlineCode",{parentName:"li"},"lzo")," ",(0,l.yg)("inlineCode",{parentName:"li"},"none")),(0,l.yg)("li",{parentName:"ul"},"orc/parquet:",(0,l.yg)("br",{parentName:"li"}),"automatically recognizes the compression type, no additional settings required.")),(0,l.yg)("h3",{id:"archive_compress_codec-string"},"archive_compress_codec ","[string]"),(0,l.yg)("p",null,"The compress codec of archive files and the details that supported as the following shown:"),(0,l.yg)("table",null,(0,l.yg)("thead",{parentName:"table"},(0,l.yg)("tr",{parentName:"thead"},(0,l.yg)("th",{parentName:"tr",align:null},"archive_compress_codec"),(0,l.yg)("th",{parentName:"tr",align:null},"file_format"),(0,l.yg)("th",{parentName:"tr",align:null},"archive_compress_suffix"))),(0,l.yg)("tbody",{parentName:"table"},(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"ZIP"),(0,l.yg)("td",{parentName:"tr",align:null},"txt,json,excel,xml"),(0,l.yg)("td",{parentName:"tr",align:null},".zip")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"TAR"),(0,l.yg)("td",{parentName:"tr",align:null},"txt,json,excel,xml"),(0,l.yg)("td",{parentName:"tr",align:null},".tar")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"TAR_GZ"),(0,l.yg)("td",{parentName:"tr",align:null},"txt,json,excel,xml"),(0,l.yg)("td",{parentName:"tr",align:null},".tar.gz")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"GZ"),(0,l.yg)("td",{parentName:"tr",align:null},"txt,json,excel,xml"),(0,l.yg)("td",{parentName:"tr",align:null},".gz")),(0,l.yg)("tr",{parentName:"tbody"},(0,l.yg)("td",{parentName:"tr",align:null},"NONE"),(0,l.yg)("td",{parentName:"tr",align:null},"all"),(0,l.yg)("td",{parentName:"tr",align:null},".*")))),(0,l.yg)("p",null,"Note: gz compressed excel file needs to compress the original file or specify the file suffix, such as e2e.xls ->e2e_test.xls.gz"),(0,l.yg)("h3",{id:"encoding-string"},"encoding ","[string]"),(0,l.yg)("p",null,"Only used when file_format_type is json,text,csv,xml.\nThe encoding of the file to read. This param will be parsed by ",(0,l.yg)("inlineCode",{parentName:"p"},"Charset.forName(encoding)"),"."),(0,l.yg)("h2",{id:"example"},"Example"),(0,l.yg)("ol",null,(0,l.yg)("li",{parentName:"ol"},"In this example, We read data from s3 path ",(0,l.yg)("inlineCode",{parentName:"li"},"s3a://seatunnel-test/seatunnel/text")," and the file type is orc in this path.\nWe use ",(0,l.yg)("inlineCode",{parentName:"li"},"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider")," to authentication so ",(0,l.yg)("inlineCode",{parentName:"li"},"access_key")," and ",(0,l.yg)("inlineCode",{parentName:"li"},"secret_key")," is required.\nAll columns in the file will be read and send to sink.")),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},'# Defining the runtime environment\nenv {\n  parallelism = 1\n  job.mode = "BATCH"\n}\n\nsource {\n  S3File {\n    path = "/seatunnel/text"\n    fs.s3a.endpoint="s3.cn-north-1.amazonaws.com.cn"\n    fs.s3a.aws.credentials.provider = "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"\n    access_key = "xxxxxxxxxxxxxxxxx"\n    secret_key = "xxxxxxxxxxxxxxxxx"\n    bucket = "s3a://seatunnel-test"\n    file_format_type = "orc"\n  }\n}\n\ntransform {\n  # If you would like to get more information about how to configure seatunnel and see full list of transform plugins,\n    # please go to https://seatunnel.apache.org/docs/transform-v2\n}\n\nsink {\n  Console {}\n}\n')),(0,l.yg)("ol",{start:2},(0,l.yg)("li",{parentName:"ol"},"Use ",(0,l.yg)("inlineCode",{parentName:"li"},"InstanceProfileCredentialsProvider")," to authentication\nThe file type in S3 is json, so need config schema option.")),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-hocon"},'\n  S3File {\n    path = "/seatunnel/json"\n    bucket = "s3a://seatunnel-test"\n    fs.s3a.endpoint="s3.cn-north-1.amazonaws.com.cn"\n    fs.s3a.aws.credentials.provider="com.amazonaws.auth.InstanceProfileCredentialsProvider"\n    file_format_type = "json"\n    schema {\n      fields {\n        id = int \n        name = string\n      }\n    }\n  }\n\n')),(0,l.yg)("ol",{start:3},(0,l.yg)("li",{parentName:"ol"},"Use ",(0,l.yg)("inlineCode",{parentName:"li"},"InstanceProfileCredentialsProvider")," to authentication\nThe file type in S3 is json and has five fields (",(0,l.yg)("inlineCode",{parentName:"li"},"id"),", ",(0,l.yg)("inlineCode",{parentName:"li"},"name"),", ",(0,l.yg)("inlineCode",{parentName:"li"},"age"),", ",(0,l.yg)("inlineCode",{parentName:"li"},"sex"),", ",(0,l.yg)("inlineCode",{parentName:"li"},"type"),"), so need config schema option.\nIn this job, we only need send ",(0,l.yg)("inlineCode",{parentName:"li"},"id")," and ",(0,l.yg)("inlineCode",{parentName:"li"},"name")," column to mysql.")),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},'# Defining the runtime environment\nenv {\n  parallelism = 1\n  job.mode = "BATCH"\n}\n\nsource {\n  S3File {\n    path = "/seatunnel/json"\n    bucket = "s3a://seatunnel-test"\n    fs.s3a.endpoint="s3.cn-north-1.amazonaws.com.cn"\n    fs.s3a.aws.credentials.provider="com.amazonaws.auth.InstanceProfileCredentialsProvider"\n    file_format_type = "json"\n    read_columns = ["id", "name"]\n    schema {\n      fields {\n        id = int \n        name = string\n        age = int\n        sex = int\n        type = string\n      }\n    }\n  }\n}\n\ntransform {\n  # If you would like to get more information about how to configure seatunnel and see full list of transform plugins,\n    # please go to https://seatunnel.apache.org/docs/transform-v2\n}\n\nsink {\n  Console {}\n}\n')),(0,l.yg)("h3",{id:"filter-file"},"Filter File"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-hocon"},'env {\n  parallelism = 1\n  job.mode = "BATCH"\n}\n\nsource {\n  S3File {\n    path = "/seatunnel/json"\n    bucket = "s3a://seatunnel-test"\n    fs.s3a.endpoint="s3.cn-north-1.amazonaws.com.cn"\n    fs.s3a.aws.credentials.provider="com.amazonaws.auth.InstanceProfileCredentialsProvider"\n    file_format_type = "json"\n    read_columns = ["id", "name"]\n    // file example abcD2024.csv\n    file_filter_pattern = "abc[DX]*.*"\n  }\n}\n\nsink {\n  Console {\n  }\n}\n')),(0,l.yg)("h2",{id:"changelog"},"Changelog"),(0,l.yg)("h3",{id:"230-beta-2022-10-20"},"2.3.0-beta 2022-10-20"),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},"Add S3File Source Connector")),(0,l.yg)("h3",{id:"next-version"},"Next version"),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},"[Feature]"," Support S3A protocol (",(0,l.yg)("a",{parentName:"li",href:"https://github.com/apache/seatunnel/pull/3632"},"3632"),")",(0,l.yg)("ul",{parentName:"li"},(0,l.yg)("li",{parentName:"ul"},"Allow user to add additional hadoop-s3 parameters"),(0,l.yg)("li",{parentName:"ul"},"Allow the use of the s3a protocol"),(0,l.yg)("li",{parentName:"ul"},"Decouple hadoop-aws dependencies"))),(0,l.yg)("li",{parentName:"ul"},"[Feature]","Set S3 AK to optional (",(0,l.yg)("a",{parentName:"li",href:"https://github.com/apache/seatunnel/pull/"},"3688"),")")),(0,l.yg)("h2",{id:"changelog-1"},"Changelog"),(0,l.yg)(r.default,{mdxType:"ChangeLog"}))}u.isMDXComponent=!0}}]);