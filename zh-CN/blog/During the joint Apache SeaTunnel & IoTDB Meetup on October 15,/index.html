<!doctype html>
<html lang="zh-CN" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Mafengwo finally chose Apache SeaTunnel after analyzing these 9 points of how it works! | Apache SeaTunnel</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://seatunnel.apache.org/zh-CN/blog/During the joint Apache SeaTunnel &amp; IoTDB Meetup on October 15,"><meta data-rh="true" name="docusaurus_locale" content="zh-CN"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="zh-CN"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Mafengwo finally chose Apache SeaTunnel after analyzing these 9 points of how it works! | Apache SeaTunnel"><meta data-rh="true" name="description" content="Bo Bi, data engineer at Mafengwo"><meta data-rh="true" property="og:description" content="Bo Bi, data engineer at Mafengwo"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2022-11-17T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Meetup"><link data-rh="true" rel="icon" href="/zh-CN/image/favicon.ico"><link data-rh="true" rel="canonical" href="https://seatunnel.apache.org/zh-CN/blog/During the joint Apache SeaTunnel &amp; IoTDB Meetup on October 15,"><link data-rh="true" rel="alternate" href="https://seatunnel.apache.org/blog/During the joint Apache SeaTunnel &amp; IoTDB Meetup on October 15," hreflang="en"><link data-rh="true" rel="alternate" href="https://seatunnel.apache.org/zh-CN/blog/During the joint Apache SeaTunnel &amp; IoTDB Meetup on October 15," hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://seatunnel.apache.org/blog/During the joint Apache SeaTunnel &amp; IoTDB Meetup on October 15," hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/zh-CN/blog/rss.xml" title="Apache SeaTunnel RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-CN/blog/atom.xml" title="Apache SeaTunnel Atom Feed">






<link rel="alternate" type="application/rss+xml" href="/zh-CN/user_cases/rss.xml" title="Apache SeaTunnel RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-CN/user_cases/atom.xml" title="Apache SeaTunnel Atom Feed">

<script>var _paq=window._paq=window._paq||[];_paq.push(["setDoNotTrack",!0]),_paq.push(["disableCookies"]),_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){var a="https://analytics.apache.org/";_paq.push(["setTrackerUrl",a+"matomo.php"]),_paq.push(["setSiteId","65"]);var e=document,p=e.createElement("script"),t=e.getElementsByTagName("script")[0];p.async=!0,p.src=a+"matomo.js",t.parentNode.insertBefore(p,t)}()</script><link rel="stylesheet" href="/zh-CN/assets/css/styles.1d2cde9b.css">
<link rel="preload" href="/zh-CN/assets/js/runtime~main.493b0a68.js" as="script">
<link rel="preload" href="/zh-CN/assets/js/main.ae1b2d26.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><div class="announcementBar_mb4j" style="background-color:rgb(70, 125, 175, 0.8)" role="banner"><div class="content_knG7 announcementBarContent_xLdY"><a href="https://github.com/apache/seatunnel" target="_blank" style="display: flex; width: 100%; align-items: center; justify-content: center; margin-left: 4px; text-decoration: none;">⭐️ If you like Apache SeaTunnel, give it a star on GitHub 
                <img style="width: 1.2rem; height: 1.2rem; margin-left: 0.4rem;" src="/home/icons/github1.svg"> ⭐️
                    </a></div></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zh-CN/"><div class="navbar__logo"><img src="/zh-CN/image/logo.png" alt="Apache SeaTunnel Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/zh-CN/image/logo.png" alt="Apache SeaTunnel Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Apache SeaTunnel</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/zh-CN/">首页</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">文档</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/zh-CN/docs/2.3.9/about">2.3.9</a></li><li><a class="dropdown__link" href="/zh-CN/docs/2.3.8/about">2.3.8</a></li><li><a class="dropdown__link" href="/zh-CN/docs/2.3.7/about">2.3.7</a></li><li><a class="dropdown__link" href="/zh-CN/docs/2.3.6/about">2.3.6</a></li><li><a class="dropdown__link" href="/zh-CN/docs/2.3.5/about">2.3.5</a></li><li><a class="dropdown__link" href="/zh-CN/docs/about">Next</a></li><li><a class="dropdown__link" href="/zh-CN/versions/">All versions</a></li></ul></div><a class="navbar__item navbar__link" href="/zh-CN/download">下载</a><a class="navbar__item navbar__link" href="/zh-CN/community/contribution_guide/contribute">社区</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh-CN/blog">博客</a><a class="navbar__item navbar__link" href="/zh-CN/user_cases">用户案例</a><a class="navbar__item navbar__link" href="/zh-CN/team">团队</a><a class="navbar__item navbar__link" href="/zh-CN/user">用户</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Apache</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">基金会</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">证书</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">事件</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">赞助</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">致谢</a></li><li><a href="https://apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li></ul></div><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a class="navbar__item navbar__link" href="/zh-CN/security">安全</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/blog/During the joint Apache SeaTunnel &amp; IoTDB Meetup on October 15," target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/zh-CN/blog/During the joint Apache SeaTunnel &amp; IoTDB Meetup on October 15," target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-CN">简体中文</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input searchInput_YFbd"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="最近博文导航"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zh-CN/blog/2023/3/31/SeaTunnel_2_3_1_Released_Refactored_AI_Compatible_Feature_Allows_ChatGPT_Automatic_Get">SeaTunnel 2.3.1 is released! The refactored AI Compatible feature allows ChatGPT to automatically generate Connector code</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zh-CN/blog/2023/3/29/Performance_Test_Report_SeaTunnel_Synchronizes_Data_in_Batches_420_Percent_Faster_than_GLUE.md">Performance Test Report: SeaTunnel Synchronizes data in batches 420% Faster than GLUE!</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zh-CN/blog/2023/02/09/SeaTunnel_Now_Supports_CDC_Writing_by_ClickHouse_Connector.md">SeaTunnel now supports CDC (Capture Change Data) writing by ClickHouse Connector!</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zh-CN/blog/Reveal the core design of the SeaTunnel Zeta synchronization engine!">In the recently released SeaTunnel 2.3.0 official version</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/zh-CN/blog/Apache IoTDB (Internet of Things Database) is a software system that integrates the collection">SeaTunnel supports IoTDB to implement IoT data synchronization</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Bo Bi, data engineer at Mafengwo"><header><h1 class="title_f1Hy" itemprop="headline">Mafengwo finally chose Apache SeaTunnel after analyzing these 9 points of how it works!</h1><div class="container_mt6G margin-vert--md"><time datetime="2022-11-17T00:00:00.000Z" itemprop="datePublished">2022年11月17日</time> · <!-- -->阅读需 19 分钟</div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p><img loading="lazy" src="/zh-CN/assets/images/16714322908857-c6ce9a962f477d13b5480206b583b6d2.jpg" width="720" height="480" class="img_ev3q"></p><p><img loading="lazy" src="/zh-CN/assets/images/16714322944041-351d2ac6aa565d636c97a1ad6b0c136e.jpg" width="360" height="309" class="img_ev3q">
Bo Bi, data engineer at Mafengwo</p><blockquote><p>During the joint Apache SeaTunnel &amp; IoTDB Meetup on October 15, Bo Bi, the data engineer at a leading Chinese travel-social e-commerce platform Mafengwo, introduced the basic principles of SeaTunnel and related enterprise practice thinking, the pain points and optimization thinking in typical scenarios of Mafengwo’s big data development and scheduling platform, and shared his experience of participating in community contributions. We hope to help you understand SeaTunnel and the paths and skills of community building at the same time.</p></blockquote><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction-to-the-technical-principle-of-seatunnel">Introduction to the technical principle of SeaTunnel<a href="#introduction-to-the-technical-principle-of-seatunnel" class="hash-link" aria-label="Introduction to the technical principle of SeaTunnel的直接链接" title="Introduction to the technical principle of SeaTunnel的直接链接">​</a></h2><p>SeaTunnel is a distributed, high-performance data integration platform for the synchronization and transformation of large volumes of data (offline and real-time)</p><p>The diagram above shows the workflow of SeaTunnel, which in simple terms consists of 3 parts: input, transformation, and output; more complex data processing is just a combination of several actions.</p><p>In a synchronization scenario, such as importing Kafka to Elasticsearch, Kafka is the Source of the process and Elasticsearch is the Sink of the process.</p><p>If, during the import process, the field columns do not match the external data columns to be written and some column or type conversion is required, or if you need to join multiple data sources and then do some data widening, field expansion, etc., then you need to add some Transform in the process, corresponding to the middle part of the picture.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714323322988-74b7a47d1a3299efd23c6375d3acaa5e.jpg" width="660" height="781" class="img_ev3q">
This shows that the core of SeaTunnel is the Source, Transform and Sink process definitions.</p><p>In Source we can define the data sources we need to read, in Sink, we can define the data pipeline and eventually write the external storage, and we can transform the data in between, either using SQL or custom functions.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-connector-api-version-v1-architecture-breakdown">SeaTunnel Connector API Version V1 Architecture Breakdown<a href="#seatunnel-connector-api-version-v1-architecture-breakdown" class="hash-link" aria-label="SeaTunnel Connector API Version V1 Architecture Breakdown的直接链接" title="SeaTunnel Connector API Version V1 Architecture Breakdown的直接链接">​</a></h2><p>For a mature component framework, there must be something unique about the design pattern of the API design implementation that makes the framework scalable.</p><p>The SeaTunnel architecture consists of three main parts.</p><p>1、SeaTunnel Basic API.</p><ol><li><p>the implementation of the SeaTunnel base API.</p></li><li><p>SeaTunnel’s plug-in system.</p></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-basic-api">SeaTunnel Basic API<a href="#seatunnel-basic-api" class="hash-link" aria-label="SeaTunnel Basic API的直接链接" title="SeaTunnel Basic API的直接链接">​</a></h2><p><img loading="lazy" src="/zh-CN/assets/images/16714323668557-9c9260e0c54017b5282b1294ccc9c692.jpg" width="720" height="194" class="img_ev3q">
The above diagram shows the definition of the interface, the Plugin interface in SeaTunnel abstracts the various actions of data processing into a Plugin.</p><p>The five parts of the diagram below, Basesource, Basetransfform, Basesink, Runtimeenv, and Execution, all inherit from the Plugin interface.
<img loading="lazy" src="/zh-CN/assets/images/16714323741126-a61ed7b20a44b14b78d39c7ffe42ec41.jpg" width="720" height="229" class="img_ev3q"></p><p>As a process definition plug-in, Source is responsible for reading data, Transform is responsible for transforming, Sink is responsible for writing and Runtimeenv is setting the base environment variables.</p><p>The overall SeaTunnel base API is shown below</p><p><img loading="lazy" src="/zh-CN/assets/images/16714323846302-eabb8409469fa34d9b0ebd2402fca23d.jpg" width="720" height="347" class="img_ev3q">
Execution, the data flow builder used to build the entire data flow based on the first three, is also part of the base API</p><p><img loading="lazy" src="/zh-CN/assets/images/16714323920717-b5bb28d92939847f1f30c61b6895191a.jpg" width="720" height="192" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-base-api-implementation">SeaTunnel Base API Implementation<a href="#seatunnel-base-api-implementation" class="hash-link" aria-label="SeaTunnel Base API Implementation的直接链接" title="SeaTunnel Base API Implementation的直接链接">​</a></h2><p>Based on the previous basic APIs, SeaTunnel has been implemented in separate packages for different computing engines, currently the Spark API abstraction and the Flink API abstraction, which logically completes the process of building the data pipeline.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714323741126-a61ed7b20a44b14b78d39c7ffe42ec41.jpg" width="720" height="229" class="img_ev3q"></p><p>Due to space constraints, we will focus on Spark batch processing. Based on the wrapped implementation of the previous base Api, the first is that Base spark source implements Base source, base Spark transform implements Base transform and Base Spark sink implements Base sink.</p><p>The method definition uses Spark’s Dataset as the carrier of the data, and all data processing is based on the Dataset, including reading, processing and exporting.</p><p>The SparkEnvironment, which internally encapsulates Spark’s Sparksession in an Env, makes it easy for individual plugins to use.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714324136843-44e65c36b7ef55c34b50a9eb0e43c3cc.jpg" width="720" height="350" class="img_ev3q"></p><p>The Spark batch process ends with SparkBatchExecution (the data stream builder), which is the core code snippet used to functionally build our data stream Pipeline, the most basic data stream on the left in the diagram below.</p><p>The user-based definition of each process component is also the configuration of Source Sink, Transform. More complex data flow logic can be implemented, such as multi-source Join, multi-pipeline processing, etc., all of which can be built through Execution.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714324237449-e5a12e608045d5a153853c93eb844852.jpg" width="720" height="405" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-connector-v1-api-architecture-summary">SeaTunnel Connector V1 API Architecture Summary<a href="#seatunnel-connector-v1-api-architecture-summary" class="hash-link" aria-label="SeaTunnel Connector V1 API Architecture Summary的直接链接" title="SeaTunnel Connector V1 API Architecture Summary的直接链接">​</a></h2><p><img loading="lazy" src="/zh-CN/assets/images/16714324336701-6e5cadce0d1a1858d7bffbf96c5cae82.jpg" width="720" height="405" class="img_ev3q">
SeaTunnel’s API consists of three main parts.</p><p>The first part is the SeaTunnel base API, which provides the basic abstract interfaces such as Source, Sink, Transform, and Plugin.</p><p>The second part is based on a set of interfaces Transform, Sink, Source, Runtime, and Execution provided by the SeaTunnel base API, which is wrapped and implemented on the Flink and Spark engines respectively, i.e. Spark engine API layer abstraction and Flink engine API layer abstraction.</p><p>Both Flink and Spark engines support stream and batch processing, so there are different ways to use streams/batches under the Flink API abstraction and Spark abstraction APIs, such as Flinkstream and Flinkbatch under the Flink abstraction API, and Sparkbatch and Sparkstreaming under the Spark abstraction API.</p><p>The third part is the plug-in system, based on Spark abstraction and Flink API abstraction, SeaTunnel engine implements rich connectors and processing plug-ins, while developers can also be based on different engine API abstractions, and extensions to achieve their own Plugin.</p><p>SeaTunnel Implementation Principle
Currently, SeaTunnel offers a variety of ways to use Flink, Spark, and FlinkSQL. Due to space limitations, we will introduce the execution principles of the Spark method.</p><p>First, the entry starts the command Start-seatunnel-spark.sh via the shell, which internally calls Sparkstarter’s Class, which parses the parameters passed by the shell script, and also parses the Config file to determine which Connectors are defined in the Config file, such as Fake, Console, etc.
<img loading="lazy" src="/zh-CN/assets/images/16714324454477-200fd76badcfc17bdd291f364c70a191.jpg" width="720" height="405" class="img_ev3q">
Then find the Connector path from the Connector plugin directory and stitch it into the Spark-submit launch command with — jar, so that the found Plugin jar package can be passed to the Spark cluster as a dependency.</p><p>For Connector plugins, all Spark Connectors are packaged in the plugin directory of the distribution (this directory is managed centrally).</p><p>After Spark-submit is executed, the task is submitted to the Spark cluster, and the Main class of the Spark job’s Driver builds the data flow Pipeline through the data flow builder Execution, combined with Souce, Sink, and Transform so that the whole chain is connected.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-connector-v2-api-architecture">SeaTunnel Connector V2 API Architecture<a href="#seatunnel-connector-v2-api-architecture" class="hash-link" aria-label="SeaTunnel Connector V2 API Architecture的直接链接" title="SeaTunnel Connector V2 API Architecture的直接链接">​</a></h2><p>In the latest community release of SeaTunnel 2.2.0-beta, the refactoring of the Connectorapi, now known as the SeaTurnelV2 API, has been completed!</p><p>Why do we need to reconfigure?</p><p>As the Container is currently a strongly coupled engine, i.e. Flink and Spark API, if the Flink or Spark engine is upgraded, the Connector will also have to be adjusted, possibly with changes to parameters or interfaces.</p><p>This can lead to multiple implementations for different engines and inconsistent parameters to develop a new Connector. Therefore, the community has designed and implemented the V2 version of the API based on these pain points.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714324726276-11d9d5c6d4e848796fa71329819caa72.jpg" width="720" height="405" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-v2-api-architecture">SeaTunnel V2 API Architecture<a href="#seatunnel-v2-api-architecture" class="hash-link" aria-label="SeaTunnel V2 API Architecture的直接链接" title="SeaTunnel V2 API Architecture的直接链接">​</a></h2><p>SeaTunnel V2 API Architecture</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1table-api">1.Table API<a href="#1table-api" class="hash-link" aria-label="1.Table API的直接链接" title="1.Table API的直接链接">​</a></h3><p>·DataType: defines SeaTunnel’s data structure SeaTunnelRow, which is used to isolate the engine</p><p>·Catalog: used to obtain Table Scheme, Options, etc..</p><p>·Catalog Storage: used to store user-defined Table Schemes etc. for unstructured engines such as Kafka.</p><p>·Table SPI: mainly used to expose the Source and Sink interfaces as an SPI</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-source--sink-api">2. Source &amp; Sink API<a href="#2-source--sink-api" class="hash-link" aria-label="2. Source &amp; Sink API的直接链接" title="2. Source &amp; Sink API的直接链接">​</a></h3><p>Define the Connector’s core programming interface for implementing the Connector</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="3engine-api">3.Engine API<a href="#3engine-api" class="hash-link" aria-label="3.Engine API的直接链接" title="3.Engine API的直接链接">​</a></h3><p>·Translation: The translation layer, which translates the Source and Sink APIs implemented by the Connector into a runnable API inside the engine.</p><p>·Execution: Execution logic, used to define the execution logic of Source, Transform, Sink and other operations within the engine.</p><p>The Source &amp; Sink API is the basis for the implementation of the connector and is very important for developers.</p><p>The design of the v2 Source &amp; Sink API is highlighted below</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-connector-v2-source-api">SeaTunnel Connector V2 Source API<a href="#seatunnel-connector-v2-source-api" class="hash-link" aria-label="SeaTunnel Connector V2 Source API的直接链接" title="SeaTunnel Connector V2 Source API的直接链接">​</a></h2><p>The current version of SeaTunnel’s API design draws on some of Flink’s design concepts, and the more core classes of the Source API are shown below.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714325444078-fbed659c615c445655896b93a093177f.jpg" width="720" height="405" class="img_ev3q">
<img loading="lazy" src="/zh-CN/assets/images/16714325474972-48cbee3672ad2f32317d48263f204978.jpg" width="720" height="405" class="img_ev3q">
The core Source API interaction flow is shown above. In the case of concurrent reads, the enumerator SourceSplitEnumerator is required to split the task and send the SourceSplit down to the SourceReader, which receives the split and uses it to read the external data source.</p><p>In order to support breakpoints and Eos semantics, it is necessary to preserve and restore the state, for example by preserving the current Reader’s Split consumption state and restoring it after a failure in each Reader through the Checkpoint state and Checkpoint mechanism, so that the data can be read from the place where it failed.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-connector-v2-sink-api">SeaTunnel Connector V2 Sink API<a href="#seatunnel-connector-v2-sink-api" class="hash-link" aria-label="SeaTunnel Connector V2 Sink API的直接链接" title="SeaTunnel Connector V2 Sink API的直接链接">​</a></h2><p><img loading="lazy" src="/zh-CN/assets/images/16714325600316-f066630b909ec30a7727b7877a4838b0.jpg" width="720" height="405" class="img_ev3q">
The overall Sink API interaction flow is shown in the diagram below. The SeaTunnel sink is currently designed to support distributed transactions, based on a two-stage transaction commit.</p><p>First SinkWriter continuously writes data to an external data source, then when the engine does a checkpoint, it triggers a first-stage commit.</p><p>SinkWriter needs to do a Prepare commit, which is the first stage of the commit.</p><p>The engine will determine if all the Writer&#x27;s first stage succeeds, and if they all succeed, the engine will combine the Subtask’s Commit info with the Commit method of the Committer to do the actual commit of the transaction and operate the database for the Commit, i.e. the second stage of the commit. This is the second stage of commit.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714325681738-973c53bd86223df4ee98cbb2ecb30eaf.jpg" width="570" height="814" class="img_ev3q">
For the Kafka sink connector implementation, the first stage is to do a pre-commit by calling KafkaProducerSender.prepareCommit().</p><p>The second commit is performed via Producer.commitTransaction();.</p><p>flush(); flushes the data from the Broker’s system cache to disk.</p><p>Finally, it is worth noting!</p><p>Both SinkCommitter and SinkAggregatedCommitter can perform a second stage commit to replace the Committer in the diagram. The difference is that SinkCommitter can only do a partial commit of a single Subtask’s CommitInfo, which may be partially successful and partially unsuccessful, and cannot be handled globally. The difference is that the SinkCommitter can only do partial commits of a single Subtask’s CommitInfo, which may be partially successful and partially unsuccessful.</p><p>SinkAggregatedCommitter is a single parallel, aggregating the CommitInfo of all Subtask, and can do the second stage commit as a whole, either all succeed or all fail, avoiding the problem of inconsistent status due to partial failure of the second stage.</p><p>It is therefore recommended that the SinkAggregatedCommitter be used in preference.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="comparison-of-seatunnel-v1-and-v2-api-processing-flows">Comparison of SeaTunnel V1 and V2 API processing flows<a href="#comparison-of-seatunnel-v1-and-v2-api-processing-flows" class="hash-link" aria-label="Comparison of SeaTunnel V1 and V2 API processing flows的直接链接" title="Comparison of SeaTunnel V1 and V2 API processing flows的直接链接">​</a></h2><p>We can look at the changes before and after the V1 V2 upgrade from a data processing perspective, which is more intuitive, Spark batch processing as an example: SeaTunnel V1: The entire data processing process is based on the Spark dataset API, and the Connector and the compute engine are strongly coupled.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714325887598-d27009789ff28e56c8bfcca29bcedfe1.jpg" width="720" height="405" class="img_ev3q">
SeaTunnel V2: Thanks to the work of the engine translator, the Connector API, and the SeaTunnelRow, the data source of the SeaTunnel internal data structures accessed through the Connector, are translated by the translation layer into a runnable Spark API and spark dataset that is recognized inside the engine during data transformation.</p><p>As data is written out, the Spark API and Spark dataset are translated through the translation layer into an executable connector API inside the SeaTunnel connector and a data source of internal SeaTunnel structures that can be used.</p><blockquote><p>Overall, the addition of a translation layer at the API and compute engine layers decouples the Connector API from the engine, and the Connector implementation no longer depends on the compute engine, making the extension and implementation more flexible.</p></blockquote><blockquote><p>In terms of community planning, the V2 API will be the main focus of development, and more features will be supported in V2, while V1 will be stabilized and no longer maintained.</p></blockquote><h2 class="anchor anchorWithStickyNavbar_LWe7" id="practice-and-reflections-on-our-off-line-development-scheduling-platform">Practice and reflections on our off-line development scheduling platform<a href="#practice-and-reflections-on-our-off-line-development-scheduling-platform" class="hash-link" aria-label="Practice and reflections on our off-line development scheduling platform的直接链接" title="Practice and reflections on our off-line development scheduling platform的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="practice-and-reflections-on-our-off-line-development-scheduling-platform-1">Practice and reflections on our off-line development scheduling platform<a href="#practice-and-reflections-on-our-off-line-development-scheduling-platform-1" class="hash-link" aria-label="Practice and reflections on our off-line development scheduling platform的直接链接" title="Practice and reflections on our off-line development scheduling platform的直接链接">​</a></h3><p><img loading="lazy" src="/zh-CN/assets/images/16714326227360-bcd55d2c5b7b23ec91a5d1e27c04fb0e.jpg" width="720" height="405" class="img_ev3q">
Hornet’s Nest Big Data Development Platform, which focuses on providing one-stop big data development and scheduling services, helps businesses solve complex problems such as data development management, task scheduling and task monitoring in offline scenarios.</p><p>The offline development and scheduling platform plays the role of the top and the bottom. The top is to provide open interface API and UI to connect with various data application platforms and businesses, and the bottom is to drive various computations and storage, and then run in an orderly manner according to the task dependency and scheduling time.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="platform-capabilities">Platform Capabilities<a href="#platform-capabilities" class="hash-link" aria-label="Platform Capabilities的直接链接" title="Platform Capabilities的直接链接">​</a></h2><p><strong>Data development</strong></p><p>Task configuration, quality testing, release live</p><p><strong>·Data synchronisation</strong></p><p>Data access, data processing, data distribution</p><p><strong>·Scheduling capabilities</strong></p><p>Supports timed scheduling, triggered scheduling</p><p><strong>·Operations and Maintenance Centre
</strong>
Job Diagnosis, Task O&amp;M, Instance O&amp;M</p><p><strong>·Management</strong></p><p>Library table management, permission management, API management, script management</p><p>In summary, the core capabilities of the offline development scheduling platform are openness, versatility, and one-stop shopping. Through standardized processes, the entire task development cycle is managed and a one-stop service experience is provided.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-architecture-of-the-platform">The architecture of the platform<a href="#the-architecture-of-the-platform" class="hash-link" aria-label="The architecture of the platform的直接链接" title="The architecture of the platform的直接链接">​</a></h2><p><img loading="lazy" src="/zh-CN/assets/images/16714326749427-2957d8414a3175ed8cc46bde32a08565.jpg" width="720" height="405" class="img_ev3q">
The Hornet’s Nest Big Data Development and Scheduling Platform consists of four main modules: the task component layer, the scheduling layer, the service layer, and the monitoring layer.</p><p>The service layer is mainly responsible for job lifecycle management (e.g. job creation, testing, release, offline); Airflow dagphthon file building and generating, task bloodline dependency management, permission management, API (providing data readiness, querying of task execution status).</p><p>The scheduling layer is based on Airflow and is responsible for the scheduling of all offline tasks.</p><p>A task component layer that enables users to develop data through supported components that include tools such as SparkSQL/, HiveSQ, LMR), StarRocks import, etc., directly interfacing with underlying HDFS, MySQL, and other storage systems.</p><p>The monitoring layer is responsible for all aspects of monitoring and alerting on scheduling resources, computing resources, task execution, etc.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="open-data-sync-capability-scenarios">Open Data Sync Capability Scenarios<a href="#open-data-sync-capability-scenarios" class="hash-link" aria-label="Open Data Sync Capability Scenarios的直接链接" title="Open Data Sync Capability Scenarios的直接链接">​</a></h2><p>Challenges with open capabilities: Need to support multiple business scenarios and meet flexible data pipeline requirements (i.e. extend to support more task components such as hive2clickhourse, clickhourse2mysql, etc.)</p><p>Extending task components based on Airflow: higher maintenance costs for extensions, need to reduce costs and increase efficiency (based on the limited provider&#x27;s Airflow offers, less applicable in terms of usage requirements, Airflow is a Python technology stack, while our team is mainly based on the Java technology stack, so the technology stack difference brings higher iteration costs)</p><p>Self-developed task components: the high cost of platform integration, long development cycle, high cost of the configuration of task components. (Research or implement task components by yourself, different ways of adapting the parameters of the components in the service layer, no uniform way of parameter configuration)</p><p>We wanted to investigate a data integration tool that, firstly, supported a rich set of components, provided out-of-the-box capabilities, was easy to extend, and offered a uniform configuration of parameters and a uniform way of using them to facilitate platform integration and maintenance.</p><ul><li>Selection of data integration tools
<img loading="lazy" src="/zh-CN/assets/images/16714327002726-6bfd742beb9534e7fdbd917db5f53d51.jpg" width="720" height="405" class="img_ev3q">
To address the pain points mentioned above, we actively explored solutions and conducted a selection analysis of several mainstream data integration products in the industry. As you can see from the comparison above, Datax and SeaTunnel both offer good scalability, and high stability, support rich connector plugins, provide scripted, uniformly configurable usage, and have active communities.</li></ul><p>However, Datax is limited by being distributed and is not well suited to massive data scenarios.</p><p>In contrast, SeaTunnel offers the ability to provide distributed execution, distributed transactions, scalable levels of data handling, and the ability to provide a unified technical solution in data synchronization scenarios.</p><p>In addition to the advantages and features described above and the applicable scenarios, more importantly, the current offline computing resources for big data are unified and managed by yarn, and for the subsequently extended tasks we also wish to execute on Yarn, we finally prefer SeaTunnel for our usage scenarios.</p><p>Further performance testing of SeaTunnel and the development of an open data scheduling platform to integrate SeaTunnel may be carried out at a later stage, and its use will be rolled out gradually.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="outbound-scenario-hive-data-sync-to-starrocks">Outbound scenario: Hive data sync to StarRocks<a href="#outbound-scenario-hive-data-sync-to-starrocks" class="hash-link" aria-label="Outbound scenario: Hive data sync to StarRocks的直接链接" title="Outbound scenario: Hive data sync to StarRocks的直接链接">​</a></h2><p>To briefly introduce the background, the Big Data platform has now completed the unification of the OLAP engine layer, using the StarRocks engine to replace the previous Kylin engine as the main query engine in OLAP scenarios.</p><p>In the data processing process, after the data is modelled in the data warehouse, the upper model needs to be imported into the OLAP engine for query acceleration, so there are a lot of tasks to push data from Hive to StarRocks every day. task (based on a wrapper for the StarRocks Broker Load import method) to a StarRocks-based table.</p><p>The current pain points are twofold.</p><p>·Long data synchronization links: Hive2StarRocks processing links, which require at least two tasks, are relatively redundant.</p><p>·Outbound efficiency: From the perspective of outbound efficiency, many Hive models themselves are processed by Spark SQL, and based on the processing the Spark Dataset in memory can be pushed directly to StarRocks without dropping the disk, improving the model’s regional time.</p><p><img loading="lazy" src="/zh-CN/assets/images/16714327218590-2644dc4ad1179eab81d40fc774d970e9.jpg" width="720" height="405" class="img_ev3q">
StarRocks currently also supports Spark Load, based on the Spark bulk data import method, but our ETL is more complex, needs to support data conversion multi-table Join, data aggregation operations, etc., so temporarily can not meet.</p><p>We know from the SeaTunnel community that there are plans to support the StarRocks Sink Connector, and we are working on that part as well, so we will continue to communicate with the community to build it together later.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-get-involved-in-community-building">How to get involved in community building<a href="#how-to-get-involved-in-community-building" class="hash-link" aria-label="How to get involved in community building的直接链接" title="How to get involved in community building的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="seatunnel-community-contribution">SeaTunnel Community Contribution<a href="#seatunnel-community-contribution" class="hash-link" aria-label="SeaTunnel Community Contribution的直接链接" title="SeaTunnel Community Contribution的直接链接">​</a></h3><p>As mentioned earlier, the community has completed the refactoring of the V1 to V2 API and needs to implement more connector plug-ins based on the V2 version of the connector API, which I was lucky enough to contribute to.</p><p>I am currently responsible for big data infrastructure work, which many mainstream big data components big data also use, so when the community proposed a connector issue, I was also very interested in it.</p><p>As the platform is also investigating SeaTunnel, learning and being able to contribute pr to the community is a great way to learn about SeaTunnel.</p><p>I remember at first I proposed a less difficult pr to implement the WeChat sink connector, but in the process of contributing I encountered many problems, bad coding style, code style did not take into account the rich output format supported by the extension, etc. Although the process was not so smooth, I was really excited and accomplished when the pr was merged. Although the process was not so smooth, it was very exciting and rewarding when the pr was merged.</p><p>As I became more familiar with the process, I became much more efficient at submitting pr and was confident enough to attempt difficult issues.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-get-involved-in-community-contributions-quickly">How to get involved in community contributions quickly<a href="#how-to-get-involved-in-community-contributions-quickly" class="hash-link" aria-label="How to get involved in community contributions quickly的直接链接" title="How to get involved in community contributions quickly的直接链接">​</a></h3><ul><li>Good first issue
Good first issue #3018 #2828</li></ul><p>If you are a first-time community contributor, it is advisable to focus on the Good first issue first, as it is basically a relatively simple and newcomer-friendly issue.</p><p>Through Good first issue, you can get familiar with the whole process of participating in the GitHub open source community contribution, for example, first fork the project, then submit the changes, and finally submit the pull request, waiting for the community to review, the community will target to you to put forward some suggestions for improvement, directly will leave a comment below, until when your pr is merged in, this will have completed a comp</p><ul><li>Subscribe to community mailings
Once you’re familiar with the pr contribution process, you can subscribe to community emails to keep up to date with what’s happening in the community, such as what features are currently being worked on and what’s planned for future iterations. If you’re interested in a feature, you can contribute to it in your own situation!</li><li>Familiarity with git use
The main git commands used in development are git clone, git pull, git rebase and git merge. git rebase is recommended in the community development specification and does not generate additional commits compared to git merge.</li><li>Familiarity with GitHub project collaboration process
Open source projects are developed collaboratively by multiple people, and the collaboration method on GitHub is at its core outlined in fork For example, the apache st project, which is under the apache space, is first forked to our own space on GitHub</li></ul><p>Then modify the implementation, mention a pull request, and submit the pull request to be associated with the issue, in the commit, if we change a long time, in the upward commit, then the target branch has a lot of new commits exhausted this time we need to do a pull&amp; merge or rebase.</p><ul><li>Source code compilation project
It is important to be familiar with source compilation, as local source compilation can prove that the code added to a project can be compiled, and can be used as a preliminary check before committing to pr. Source compilation is generally slow and can be speeded up by using mvn -T for multi-threaded parallel compilation.</li><li>Compilation checks
Pre-compilation checks, including Licence header, Code checkstyle, and Document checkstyle, will be checked during Maven compilation, and if they fail, the CI will not be passed. So it is recommended to use some plug-in tools in the idea to improve the efficiency, such as Code checkstyle has a plug-in to automatically check the code specification, Licence header can add code templates in the idea, these have been shared by the community before how to do!</li><li>Add full E2E</li></ul><p>Add full E2E testing and ensure that the E2E is passed before the Pull request.</p><p>Finally, I hope more students will join the SeaTunnel community, where you can not only feel the open-source spirit and culture of Apache but also understand the management process of Apache projects and learn good code design ideas.</p><p>We hope that by working together and growing together, we can build SeaTunnel into a top-notch data integration platform.</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>标签：</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/zh-CN/blog/tags/meetup">Meetup</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/apache/seatunnel-website/edit/main/blog/2022-11-17-Mafengwo-finally-chose-Apache-SeaTunnel-after-analyzing-these-9-points-of-how-it-works.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="博文分页导航"><a class="pagination-nav__link pagination-nav__link--prev" href="/zh-CN/blog/Apache SeaTunnel Committer | Zongwen Li"><div class="pagination-nav__sublabel">较新一篇</div><div class="pagination-nav__label">SeaTunnel engine, designed for tens-of-billions data integration</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/zh-CN/blog/2022/09/20/A-tutorial-to-help-you develop-a-SeaTunnel-Connector-hand-by-hand-while-avoiding -pitfalls"><div class="pagination-nav__sublabel">较旧一篇</div><div class="pagination-nav__label">A tutorial to help you develop a SeaTunnel Connector hand-by-hand while avoiding pitfalls</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction-to-the-technical-principle-of-seatunnel" class="table-of-contents__link toc-highlight">Introduction to the technical principle of SeaTunnel</a></li><li><a href="#seatunnel-connector-api-version-v1-architecture-breakdown" class="table-of-contents__link toc-highlight">SeaTunnel Connector API Version V1 Architecture Breakdown</a></li><li><a href="#seatunnel-basic-api" class="table-of-contents__link toc-highlight">SeaTunnel Basic API</a></li><li><a href="#seatunnel-base-api-implementation" class="table-of-contents__link toc-highlight">SeaTunnel Base API Implementation</a></li><li><a href="#seatunnel-connector-v1-api-architecture-summary" class="table-of-contents__link toc-highlight">SeaTunnel Connector V1 API Architecture Summary</a></li><li><a href="#seatunnel-connector-v2-api-architecture" class="table-of-contents__link toc-highlight">SeaTunnel Connector V2 API Architecture</a></li><li><a href="#seatunnel-v2-api-architecture" class="table-of-contents__link toc-highlight">SeaTunnel V2 API Architecture</a><ul><li><a href="#1table-api" class="table-of-contents__link toc-highlight">1.Table API</a></li><li><a href="#2-source--sink-api" class="table-of-contents__link toc-highlight">2. Source &amp; Sink API</a></li><li><a href="#3engine-api" class="table-of-contents__link toc-highlight">3.Engine API</a></li></ul></li><li><a href="#seatunnel-connector-v2-source-api" class="table-of-contents__link toc-highlight">SeaTunnel Connector V2 Source API</a></li><li><a href="#seatunnel-connector-v2-sink-api" class="table-of-contents__link toc-highlight">SeaTunnel Connector V2 Sink API</a></li><li><a href="#comparison-of-seatunnel-v1-and-v2-api-processing-flows" class="table-of-contents__link toc-highlight">Comparison of SeaTunnel V1 and V2 API processing flows</a></li><li><a href="#practice-and-reflections-on-our-off-line-development-scheduling-platform" class="table-of-contents__link toc-highlight">Practice and reflections on our off-line development scheduling platform</a><ul><li><a href="#practice-and-reflections-on-our-off-line-development-scheduling-platform-1" class="table-of-contents__link toc-highlight">Practice and reflections on our off-line development scheduling platform</a></li></ul></li><li><a href="#platform-capabilities" class="table-of-contents__link toc-highlight">Platform Capabilities</a></li><li><a href="#the-architecture-of-the-platform" class="table-of-contents__link toc-highlight">The architecture of the platform</a></li><li><a href="#open-data-sync-capability-scenarios" class="table-of-contents__link toc-highlight">Open Data Sync Capability Scenarios</a></li><li><a href="#outbound-scenario-hive-data-sync-to-starrocks" class="table-of-contents__link toc-highlight">Outbound scenario: Hive data sync to StarRocks</a></li><li><a href="#how-to-get-involved-in-community-building" class="table-of-contents__link toc-highlight">How to get involved in community building</a><ul><li><a href="#seatunnel-community-contribution" class="table-of-contents__link toc-highlight">SeaTunnel Community Contribution</a></li><li><a href="#how-to-get-involved-in-community-contributions-quickly" class="table-of-contents__link toc-highlight">How to get involved in community contributions quickly</a></li></ul></li></ul></div></div></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">SeaTunnel</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/zh-CN/docs/faq">FAQ</a></li><li class="footer__item"><a href="https://github.com/apache/incubator-seatunnel/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item">版本<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">社区</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-seatunnel/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issue Tracker<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-seatunnel/pulls" target="_blank" rel="noopener noreferrer" class="footer__link-item">Pull Requests<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">订阅邮件组</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/zh-CN/community/contribution_guide/subscribe">How to Subscribe</a></li><li class="footer__item"><a href="mailto:dev-subscribe@seatunnel.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">订阅邮件<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://lists.apache.org/list.html?dev@seatunnel.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">邮件归档<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div style="margin-top: 20px;background: #f4f8fa">
                <img style="height:50px;margin-bottom: 10px" alt="Apache Software Foundation" src="/zh-CN/image/incubator-logo.svg">
                <p style="color: #999999;font-weight:400;text-align:left">Apache SeaTunnel is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.</p>
                <div style="border-top: 1px solid #ccc;min-height: 60px;line-height: 20px;text-align: center;font-family: Avenir-Medium;font-size: 14px;color: #999;display: flex;align-items: center;"><span>Copyright © 2021-2022 The Apache Software Foundation. Apache SeaTunnel, SeaTunnel, and its feather logo are trademarks of The Apache Software Foundation.</span></div>
                <div style="text-align: center;">
                    <a href="https://twitter.com/asfseatunnel?s=21" target="_blank" title="Twitter"><svg t="1644553365083" class="icon" viewBox="0 0 1260 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="7015" width="25" height="25"><path d="M1259.846921 121.148242c-46.524504 20.728739-96.273478 34.547899-148.325646 40.536201 53.434084-31.784067 94.430924-82.454319 113.777747-142.797982-50.209613 29.480874-105.486251 51.13089-164.447999 62.646857A257.584528 257.584528 0 0 0 872.449815 0.000276c-142.797982 0-258.418284 115.620302-258.418284 258.418284 0 20.268101 2.303193 40.075563 6.909579 58.961748C405.82286 306.32498 215.579097 203.602561 87.98219 47.446058c-22.110655 38.233008-35.008538 82.454319-35.008538 129.900099 0 89.824537 45.603227 168.593747 115.159663 215.118251-42.378756-1.381916-81.99368-12.897882-117.002217-32.244706v3.224471c0 125.293713 88.90326 229.398049 207.287393 253.351259-21.650017 5.988302-44.681949 9.212773-68.17452 9.212773-16.582991 0-32.705344-1.842555-48.827697-4.606387 32.705344 102.722419 128.518184 177.345881 241.374653 179.649074-88.442621 69.095798-199.917175 110.553277-321.06514 110.553277-20.728739 0-41.457479-1.381916-61.72558-3.685109 114.238386 73.241546 250.126788 116.08094 396.149241 116.08094 475.379089 0 735.179289-393.846048 735.179289-735.179289 0-11.055328-0.460639-22.571294-0.921277-33.626621 51.13089-36.851092 94.891562-82.454319 129.439461-134.045848z" fill="#909094" p-id="7016"></path></svg></a> 
                    <a href="https://apacheseatunnel.slack.com" target="_blank" title="Slack" style="margin-left: 20px;"><svg t="1644553076784" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3088" width="23" height="23"><path d="M215.125333 647.04a107.861333 107.861333 0 0 1-107.52 107.648A107.861333 107.861333 0 0 1 0 647.04a107.818667 107.818667 0 0 1 107.605333-107.52h107.52v107.52z m54.229334 0a107.818667 107.818667 0 0 1 107.562666-107.52 107.818667 107.818667 0 0 1 107.562667 107.52v269.354667A107.861333 107.861333 0 0 1 376.917333 1024a107.861333 107.861333 0 0 1-107.562666-107.605333v-269.354667zM376.917333 215.125333a107.861333 107.861333 0 0 1-107.562666-107.52A107.861333 107.861333 0 0 1 376.917333 0a107.861333 107.861333 0 0 1 107.562667 107.605333v107.52H376.917333z m0 54.229334a107.861333 107.861333 0 0 1 107.562667 107.562666 107.861333 107.861333 0 0 1-107.562667 107.562667H107.605333A107.861333 107.861333 0 0 1 0 376.917333a107.861333 107.861333 0 0 1 107.605333-107.562666h269.312z m431.872 107.562666a107.861333 107.861333 0 0 1 107.605334-107.562666A107.861333 107.861333 0 0 1 1024 376.917333a107.861333 107.861333 0 0 1-107.605333 107.562667h-107.605334V376.917333z m-54.101333 0a107.861333 107.861333 0 0 1-107.648 107.562667 107.818667 107.818667 0 0 1-107.52-107.562667V107.605333A107.818667 107.818667 0 0 1 647.04 0a107.861333 107.861333 0 0 1 107.648 107.605333v269.312z m-107.648 431.872a107.861333 107.861333 0 0 1 107.648 107.605334A107.861333 107.861333 0 0 1 647.04 1024a107.818667 107.818667 0 0 1-107.52-107.605333v-107.605334h107.52z m0-54.101333a107.818667 107.818667 0 0 1-107.52-107.648 107.776 107.776 0 0 1 107.52-107.52h269.354667A107.818667 107.818667 0 0 1 1024 647.04a107.861333 107.861333 0 0 1-107.605333 107.648h-269.354667z" p-id="3089" fill="#909094"></path></svg></a> 
                    <a href="https://lists.apache.org/list.html?dev@seatunnel.apache.org" target="_blank" title="Mailing list" style="margin-left: 20px;"><svg t="1644553175467" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5304" width="26" height="26"><path d="M853.333333 170.666667H170.666667c-46.933333 0-85.333333 38.4-85.333334 85.333333v512c0 46.933333 38.4 85.333333 85.333334 85.333333h682.666666c46.933333 0 85.333333-38.4 85.333334-85.333333V256c0-46.933333-38.4-85.333333-85.333334-85.333333z m0 170.666666l-341.333333 213.333334-341.333333-213.333334V256l341.333333 213.333333 341.333333-213.333333v85.333333z" p-id="5305" fill="#909094"></path></svg></a> 
                    <a href="https://github.com/apache/incubator-seatunnel" target="_blank" title="GitHub" style="margin-left: 20px;"><svg t="1644553223000" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6156" width="23" height="23"><path d="M512 12.64c-282.752 0-512 229.216-512 512 0 226.208 146.72 418.144 350.144 485.824 25.6 4.736 35.008-11.104 35.008-24.64 0-12.192-0.48-52.544-0.704-95.328-142.464 30.976-172.512-60.416-172.512-60.416-23.296-59.168-56.832-74.912-56.832-74.912-46.464-31.776 3.52-31.136 3.52-31.136 51.392 3.616 78.464 52.768 78.464 52.768 45.664 78.272 119.776 55.648 148.992 42.56 4.576-33.088 17.856-55.68 32.512-68.48-113.728-12.928-233.28-56.864-233.28-253.024 0-55.904 20-101.568 52.768-137.44-5.312-12.896-22.848-64.96 4.96-135.488 0 0 43.008-13.76 140.832 52.48a491.296 491.296 0 0 1 128.16-17.248c43.488 0.192 87.328 5.888 128.256 17.248 97.728-66.24 140.64-52.48 140.64-52.48 27.872 70.528 10.336 122.592 5.024 135.488 32.832 35.84 52.704 81.536 52.704 137.44 0 196.64-119.776 239.936-233.792 252.64 18.368 15.904 34.72 47.04 34.72 94.816 0 68.512-0.608 123.648-0.608 140.512 0 13.632 9.216 29.6 35.168 24.576C877.472 942.624 1024 750.784 1024 524.64c0-282.784-229.248-512-512-512z" p-id="6157" fill="#909094"></path></svg></a> 
                </div>
            <div></div></div></div></div></div></footer></div>
<script src="/zh-CN/assets/js/runtime~main.493b0a68.js"></script>
<script src="/zh-CN/assets/js/main.ae1b2d26.js"></script>
</body>
</html>